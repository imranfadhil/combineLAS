{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add a new cell, type '# %%'\n",
    "# To add a new markdown cell, type '# %% [markdown]'\n",
    "# %%\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sqlite3 as sql\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.width', 500)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "db = sql.connect('../data/combinedLAS_v2.db')\n",
    "\n",
    "#%%\n",
    "dfa = pd.read_sql('SELECT * FROM all_LAS',db)\n",
    "dfa.tail()\n",
    "\n",
    "# %%\n",
    "# Load selected features from SQL into dataframe\n",
    "dfs = pd.read_sql('SELECT TVDSS,WELLNAME,GR,RTC,NPHIC,RHOBC,SWT,FLUID,KLOG,PHIT_HC FROM all_LAS\\\n",
    "                            WHERE GR IS NOT NULL\\\n",
    "                            AND RTC IS NOT NULL\\\n",
    "                            AND NPHIC IS NOT NULL\\\n",
    "                            AND RHOBC IS NOT NULL\\\n",
    "                            AND TVDSS IS NOT NULL\\\n",
    "                            AND SWT IS NOT NULL\\\n",
    "                            AND KLOG IS NOT NULL\\\n",
    "                            AND PHIT_HC IS NOT NULL\\\n",
    "                            AND FLUID IS NOT NULL', db)#, index_col='index')\n",
    "print(dfs.shape)\n",
    "dfs.head()\n",
    "#df.to_sql('selected_LAS', db, if_exists='replace')\n",
    "\n",
    "#%%\n",
    "df = pd.read_sql('SELECT * FROM cleaned_LAS',db,index_col='index')\n",
    "df.head()\n",
    "\n",
    "#%%\n",
    "#dfc.to_sql('cleaned_LAS', db, if_exists='replace')\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Merge similar log types on all_LAS dataframe\n",
    "\n",
    "#dfa[['DEN','RHOB']].describe()\n",
    "rRHOB = dfa[(dfa.DEN.isna() | (dfa.DEN <0))& dfa.RHOB.notna()][['DEN','RHOB']]\n",
    "rNPHI = dfa[(dfa.NEUT.isna() | dfa.NEUT<-0.02)& dfa.NPHI_COR.notna()][['NEUT','NPHI_COR']]\n",
    "rRT = dfa[dfa.LLD.isna() & dfa.RT.notna()][['LLD','RT']]\n",
    "print('%s \\n\\n%s \\n\\n%s' % (rRHOB.count(), rNPHI.count(), rRT.count()))\n",
    "\n",
    "dfa['RHOBC'] = np.where(dfa.DEN.isna(), dfa.RHOB, dfa.DEN)\n",
    "dfa['RHOBC'] = np.where(dfa.RHOBC<0, dfa.RHOB, dfa.RHOBC)\n",
    "\n",
    "dfa['NPHIC'] = np.where(dfa.NEUT.isna(), dfa.NPHI_COR, dfa.NEUT)\n",
    "dfa['NPHIC'] = np.where(dfa.NPHIC<-0.02, dfa.NPHI_COR, dfa.NPHIC)\n",
    "dfa['NPHIC'] = np.where(dfa.NPHIC>=1, dfa.NPHIC/100, dfa.NPHIC)\n",
    "dfa['NPHIC'] = np.where(dfa.NPHIC>=1, np.nan, dfa.NPHIC)\n",
    "\n",
    "dfa['RTC'] = np.where(dfa.LLD.isna(), dfa.RT, dfa.LLD)\n",
    "dfa['RTC'] = np.where(dfa.RTC<0, np.nan, dfa.RTC)\n",
    "print('\\nMissing values (pct): \\n %s' % round(dfa.isna().sum()/dfa.shape[0]*100,2).sort_values())\n",
    "\n",
    "\n",
    "#%% \n",
    "# Data QC\n",
    "print('Dataframe shape: %d, %d' % dfs.shape)\n",
    "print('\\nMissing values, (pct): \\n %s' % round(dfs.isna().sum()/dfs.shape[0]*100,2).sort_values())\n",
    "print('\\nDescibe(); \\n %s' % round(dfs.describe(),2))\n",
    "print('\\nKurtosis(); \\n %s' % round(dfs.kurt()))\n",
    "print('\\nSkew(); \\n %s' % round(dfs.skew()))\n",
    "dfs.hist(figsize=(10,10), bins=20)\n",
    "\n",
    "\n",
    "#%% \n",
    "# Data QC\n",
    "print('Dataframe shape: %d, %d' % df.shape)\n",
    "print('\\nMissing values, (pct): \\n %s' % round(df.isna().sum()/df.shape[0]*100,2).sort_values())\n",
    "print('\\nDescibe(); \\n %s' % round(df.describe(),2))\n",
    "print('\\nKurtosis(); \\n %s' % round(df.kurt()))\n",
    "print('\\nSkew(); \\n %s' % round(df.skew()))\n",
    "df.hist(figsize=(10,10), bins=20)\n",
    "\n",
    "# %%\n",
    "# List missing data by Well\n",
    "print('\\nNumber  of rows by well: ')\n",
    "g = df.groupby('WELLNAME')\n",
    "#g.count().rsub(g.size(), axis=0)\n",
    "#g.count().rsub(g.size(), axis=0).sum(axis=1).sort_values()\n",
    "g.count().sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "\n",
    "#%%\n",
    "# Clean out of range data/ features\n",
    "dfc=df\n",
    "print(round(dfc.describe(),2))\n",
    "\n",
    "dfc.GR = np.where(dfc.GR>250,np.nan,dfc.GR)\n",
    "dfc.RTC = np.where(dfc.RTC>200,np.nan,dfc.RTC)\n",
    "dfc.NPHIC = np.where(dfc.NPHIC>.5,np.nan,dfc.NPHIC)\n",
    "dfc.RHOBC = np.where(dfc.RHOBC>3,np.nan,dfc.RHOBC)\n",
    "dfc.RHOBC = np.where(dfc.RHOBC<1.1,np.nan,dfc.RHOBC)\n",
    "dfc.KLOG = np.where(dfc.KLOG>2000,2000,dfc.KLOG)\n",
    "dfc.PHIT_HC = np.where(dfc.PHIT_HC>.5,np.nan,dfc.PHIT_HC)\n",
    "\n",
    "dfc.dropna(inplace=True)\n",
    "print(round(dfc.describe(),2))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Normalize data and check correlation\n",
    "dfn = df\n",
    "df_norm = (\n",
    "    dfn.groupby(\"WELLNAME\")\n",
    "    .apply(SklearnWrapper(preprocessing.MinMaxScaler()))#StandardScaler()))\n",
    "    #.drop(\"WEclass\", axis=\"columns\")\n",
    ")\n",
    "df_norm['WELLNAME'] = dfn['WELLNAME']\n",
    "print(df_norm.columns)\n",
    "print(round(df_norm.describe(),2))\n",
    "\n",
    "print('\\nCorrelation for all wells (normalized)')\n",
    "dfcorr = df_norm.corr(method='kendall')\n",
    "sn.heatmap(dfcorr, annot=True,fmt='.2f')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#%%\n",
    "dfn45 = df_norm[df_norm['WELLNAME']=='WELL-45']\n",
    "dfn45.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "print('Modelling regressors on SWT for Well-45')\n",
    "\n",
    "\"\"\" X = df_norm.iloc[:,0:5]\n",
    "y = df_norm.iloc[:,5] # Target variable \"\"\"\n",
    "X = dfn45.iloc[:,0:5]\n",
    "y = dfn45.iloc[:,5] # Target variable\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "print('Target variable: SWT, Features: TVDSS, GR, RTC, NPHIC, RHOBC') \n",
    "# SWT\n",
    "compareRModels()\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "# Tuning SVR parameters for estimator\n",
    "param = {'kernel':('poly', 'sigmoid','rbf'), 'C':[1, 2, 3]}\n",
    "GS_CV = GridSearchCV(SVR(),param)\n",
    "GS_CV.fit(X_train, Y_train)\n",
    "print(GS_CV.get_params())\n",
    "#est.predict(X_validation)\n",
    "print(GS_CV.score(X_validation,Y_validation))\n",
    "print(GS_CV.best_params_)\n",
    "\n",
    "#%%\n",
    "est = SVR(C=3,kernel='poly')\n",
    "est.fit(X_train, Y_train)\n",
    "est.score(X_validation,Y_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def compareCModels():#X_train, Y_train):\n",
    "    # Spot Check Algorithms\n",
    "    models = []\n",
    "    models.append(('LR', LogisticRegression()))\n",
    "    models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "    models.append(('KNNC', KNeighborsClassifier()))    \n",
    "    models.append(('CART', DecisionTreeClassifier()))    \n",
    "    models.append(('NB', GaussianNB()))        \n",
    "    models.append(('SVC', SVC(gamma='auto')))   \n",
    "    # evaluate each model in turn\n",
    "    results = []\n",
    "    names = []\n",
    "    mean_results = []\n",
    "    for name, model in models:\n",
    "        kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "        cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy') #cv=kfold\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        mean_results.append(cv_results.mean())\n",
    "        print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "    \n",
    "    plt.boxplot(results, labels=names)\n",
    "    plt.title('Algorithm Comparison')\n",
    "    plt.show()\n",
    "\n",
    "    bestModel = models[np.nanargmax(mean_results)][1]\n",
    "    print('\\nBest model: %s' % (bestModel))\n",
    "    modelScore(bestModel)\n",
    "    return bestModel\n",
    "\n",
    "def compareRModels():#X_train, Y_train):\n",
    "    # Spot Check Algorithms\n",
    "    models = []    \n",
    "    models.append(('KNNR', KNeighborsRegressor()))    \n",
    "    models.append(('DTR', DecisionTreeRegressor()))\n",
    "    models.append(('ADAB', AdaBoostRegressor()))       \n",
    "    models.append(('GPR', GaussianProcessRegressor()))    \n",
    "    #models.append(('SVR', SVR(gamma='auto')))\n",
    "    models.append(('MLPR', MLPRegressor(random_state=1)))\n",
    "    # evaluate each model in turn\n",
    "    results = []\n",
    "    names = []\n",
    "    mean_results = []\n",
    "    for name, model in models:\n",
    "        cv_results = cross_val_score(model, X_train, Y_train, scoring='r2')\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        mean_results.append(cv_results.mean())\n",
    "        print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "    \n",
    "    plt.boxplot(results, labels=names)\n",
    "    plt.title('Algorithm Comparison')\n",
    "    plt.show()\n",
    "\n",
    "    bestModel = models[np.nanargmax(mean_results)][1]\n",
    "    print('\\nBest model: %s' % (bestModel))\n",
    "    modelScore(bestModel)\n",
    "\n",
    "\n",
    "def modelScore(model):\n",
    "    #model = GaussianNB()\n",
    "    model.fit(X_train, Y_train)\n",
    "    predictions = model.predict(X_validation)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    try:\n",
    "        print('Accuracy score: %f' % (accuracy_score(Y_validation, predictions)))\n",
    "        #print(confusion_matrix(Y_validation, predictions))\n",
    "        print('Classification report: \\n %s' % (classification_report(Y_validation, predictions)))\n",
    "    except:\n",
    "        print('R2: %f' % (model.score(X_train, Y_train)))\n",
    "        #print(confusion_matrix(Y_validation, predictions))\n",
    "        #print('Classification report: \\n %s' % \n",
    "\n",
    "import typing\n",
    "class SklearnWrapper:\n",
    "    def __init__(self, transform: typing.Callable):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, df):\n",
    "        transformed = self.transform.fit_transform(df.values)\n",
    "        return pd.DataFrame(transformed, columns=df.columns, index=df.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
